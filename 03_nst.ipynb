{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2020-09-23T16:11:58.787399Z",
     "shell.execute_reply": "2020-09-23T16:11:58.787399Z",
     "shell.execute_reply.started": "2020-09-23T16:11:55.944601Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NST\n",
    "\n",
    "- input: content image, style image\n",
    "- output: generate image like (content + style) from noise image by using gradient descent\n",
    "\n",
    "## References\n",
    "\n",
    "- https://keras.io/examples/generative/neural_style_transfer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load VGG-19 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:11:58.789389Z",
     "iopub.status.busy": "2020-09-23T16:11:58.788391Z",
     "iopub.status.idle": "2020-09-23T16:11:58.795373Z",
     "shell.execute_reply": "2020-09-23T16:11:58.794376Z",
     "shell.execute_reply.started": "2020-09-23T16:11:58.789389Z"
    }
   },
   "outputs": [],
   "source": [
    "# neural style transfer output\n",
    "\n",
    "content_layers = ['block5_conv2']\n",
    "style_layers = [\n",
    "    'block1_conv1',\n",
    "    'block2_conv1',\n",
    "    'block3_conv1',\n",
    "    'block4_conv1',\n",
    "    'block5_conv1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:11:58.797367Z",
     "iopub.status.busy": "2020-09-23T16:11:58.797367Z",
     "iopub.status.idle": "2020-09-23T16:11:58.814321Z",
     "shell.execute_reply": "2020-09-23T16:11:58.813324Z",
     "shell.execute_reply.started": "2020-09-23T16:11:58.797367Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_vgg():\n",
    "    vgg = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "    # vgg.trainable = False\n",
    "    \n",
    "    # extracted feature\n",
    "    layers = content_layers + style_layers\n",
    "    outputs_dict = dict([(layer, vgg.get_layer(layer).output) for layer in layers])\n",
    "    \n",
    "    # model for nst\n",
    "    feature_extractor = tf.keras.Model(inputs=vgg.input, outputs=outputs_dict)\n",
    "    \n",
    "    return feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:11:58.816327Z",
     "iopub.status.busy": "2020-09-23T16:11:58.815319Z",
     "iopub.status.idle": "2020-09-23T16:11:58.826289Z",
     "shell.execute_reply": "2020-09-23T16:11:58.825293Z",
     "shell.execute_reply.started": "2020-09-23T16:11:58.816327Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, image_size=(500, 500)):\n",
    "    \"\"\"\n",
    "        return: tensor type array. shape (1, height, width, channel).\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    img = tf.keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=image_size \n",
    "    )\n",
    "    \n",
    "    # image to numpy array shape (h, w, c)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    \n",
    "    # to shape (1, h, w, c)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.vgg19.preprocess_input(img)\n",
    "    \n",
    "    return tf.convert_to_tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:11:58.828285Z",
     "iopub.status.busy": "2020-09-23T16:11:58.827287Z",
     "iopub.status.idle": "2020-09-23T16:11:58.845240Z",
     "shell.execute_reply": "2020-09-23T16:11:58.843245Z",
     "shell.execute_reply.started": "2020-09-23T16:11:58.828285Z"
    }
   },
   "outputs": [],
   "source": [
    "def deprocess_image(tensor_img):\n",
    "    img = np.array(tensor_img.numpy()[0], dtype=np.float64)\n",
    "    img[:, :, 0] += 103.939\n",
    "    img[:, :, 1] += 116.779\n",
    "    img[:, :, 2] += 123.68\n",
    "    img = img[:, :, ::-1]\n",
    "    img = np.clip(img, 0, 255).astype(\"uint8\")\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:11:58.847234Z",
     "iopub.status.busy": "2020-09-23T16:11:58.846237Z",
     "iopub.status.idle": "2020-09-23T16:12:00.578678Z",
     "shell.execute_reply": "2020-09-23T16:12:00.577748Z",
     "shell.execute_reply.started": "2020-09-23T16:11:58.847234Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = \"./img/2valk.jpg\"\n",
    "img_tensor = preprocess_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.579675Z",
     "iopub.status.busy": "2020-09-23T16:12:00.579675Z",
     "iopub.status.idle": "2020-09-23T16:12:00.591643Z",
     "shell.execute_reply": "2020-09-23T16:12:00.590646Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.579675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 500, 500, 3), dtype=float32, numpy=\n",
       "array([[[[  26.060997 ,   -0.7789993,  -13.68     ],\n",
       "         [  42.060997 ,   14.221001 ,    4.3199997],\n",
       "         [  70.061    ,   42.221    ,   33.32     ],\n",
       "         ...,\n",
       "         [ -57.939003 ,  -89.779    , -104.68     ],\n",
       "         [ -53.939003 ,  -85.779    , -100.68     ],\n",
       "         [ -57.939003 ,  -89.779    , -104.68     ]],\n",
       "\n",
       "        [[  44.060997 ,   21.221    ,   -2.6800003],\n",
       "         [  73.061    ,   50.221    ,   26.32     ],\n",
       "         [  36.060997 ,   13.221001 ,  -10.68     ],\n",
       "         ...,\n",
       "         [ -47.939003 ,  -83.779    ,  -98.68     ],\n",
       "         [ -49.939003 ,  -85.779    , -100.68     ],\n",
       "         [ -48.939003 ,  -84.779    ,  -99.68     ]],\n",
       "\n",
       "        [[  80.061    ,   55.221    ,   42.32     ],\n",
       "         [  59.060997 ,   33.221    ,   12.32     ],\n",
       "         [  61.060997 ,   38.221    ,   14.32     ],\n",
       "         ...,\n",
       "         [ -44.939003 ,  -84.779    , -101.68     ],\n",
       "         [ -50.939003 ,  -90.779    , -107.68     ],\n",
       "         [ -45.939003 ,  -85.779    , -102.68     ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -42.939003 ,  -58.779    ,  -63.68     ],\n",
       "         [ -36.939003 ,  -52.779    ,  -57.68     ],\n",
       "         [ -32.939003 ,  -48.779    ,  -53.68     ],\n",
       "         ...,\n",
       "         [  49.060997 ,   66.221    ,   94.32     ],\n",
       "         [  52.060997 ,   70.221    ,   94.32     ],\n",
       "         [  46.060997 ,   67.221    ,   90.32     ]],\n",
       "\n",
       "        [[ -35.939003 ,  -51.779    ,  -56.68     ],\n",
       "         [ -41.939003 ,  -57.779    ,  -62.68     ],\n",
       "         [ -48.939003 ,  -64.779    ,  -69.68     ],\n",
       "         ...,\n",
       "         [  31.060997 ,   50.221    ,   84.32     ],\n",
       "         [  29.060997 ,   48.221    ,   76.32     ],\n",
       "         [  46.060997 ,   68.221    ,   95.32     ]],\n",
       "\n",
       "        [[ -30.939003 ,  -46.779    ,  -51.68     ],\n",
       "         [ -37.939003 ,  -53.779    ,  -58.68     ],\n",
       "         [ -29.939003 ,  -45.779    ,  -50.68     ],\n",
       "         ...,\n",
       "         [ -19.939003 ,    5.2210007,   46.32     ],\n",
       "         [ -15.939003 ,    8.221001 ,   45.32     ],\n",
       "         [  17.060997 ,   39.221    ,   75.32     ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.596630Z",
     "iopub.status.busy": "2020-09-23T16:12:00.594635Z",
     "iopub.status.idle": "2020-09-23T16:12:00.638549Z",
     "shell.execute_reply": "2020-09-23T16:12:00.638549Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.596630Z"
    }
   },
   "outputs": [],
   "source": [
    "img_np = deprocess_image(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.642507Z",
     "iopub.status.busy": "2020-09-23T16:12:00.642507Z",
     "iopub.status.idle": "2020-09-23T16:12:00.650485Z",
     "shell.execute_reply": "2020-09-23T16:12:00.649488Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.642507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[109, 116, 129],\n",
       "        [127, 131, 145],\n",
       "        [156, 159, 173],\n",
       "        ...,\n",
       "        [ 18,  27,  45],\n",
       "        [ 22,  31,  49],\n",
       "        [ 18,  27,  45]],\n",
       "\n",
       "       [[120, 138, 147],\n",
       "        [149, 167, 176],\n",
       "        [112, 130, 139],\n",
       "        ...,\n",
       "        [ 24,  33,  55],\n",
       "        [ 22,  31,  53],\n",
       "        [ 23,  32,  54]],\n",
       "\n",
       "       [[165, 172, 183],\n",
       "        [135, 150, 162],\n",
       "        [137, 155, 164],\n",
       "        ...,\n",
       "        [ 21,  32,  58],\n",
       "        [ 15,  26,  52],\n",
       "        [ 20,  31,  57]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 59,  58,  60],\n",
       "        [ 65,  64,  66],\n",
       "        [ 69,  68,  70],\n",
       "        ...,\n",
       "        [217, 183, 152],\n",
       "        [217, 187, 155],\n",
       "        [213, 184, 149]],\n",
       "\n",
       "       [[ 66,  65,  67],\n",
       "        [ 60,  59,  61],\n",
       "        [ 53,  52,  54],\n",
       "        ...,\n",
       "        [207, 167, 134],\n",
       "        [199, 165, 132],\n",
       "        [218, 185, 149]],\n",
       "\n",
       "       [[ 71,  70,  72],\n",
       "        [ 64,  63,  65],\n",
       "        [ 72,  71,  73],\n",
       "        ...,\n",
       "        [169, 122,  83],\n",
       "        [168, 125,  87],\n",
       "        [198, 156, 120]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generated Image Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.652481Z",
     "iopub.status.busy": "2020-09-23T16:12:00.652481Z",
     "iopub.status.idle": "2020-09-23T16:12:00.670432Z",
     "shell.execute_reply": "2020-09-23T16:12:00.669436Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.652481Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_random_noise_tensor(img_tensor):\n",
    "    random_noise = np.array(np.random.randint(0, 255, img_tensor.shape))\n",
    "    gen_tensor = tf.Variable(random_noise, dtype=tf.float32)\n",
    "    return gen_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.673424Z",
     "iopub.status.busy": "2020-09-23T16:12:00.672428Z",
     "iopub.status.idle": "2020-09-23T16:12:00.837567Z",
     "shell.execute_reply": "2020-09-23T16:12:00.837567Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.673424Z"
    }
   },
   "outputs": [],
   "source": [
    "gen_tensor = load_random_noise_tensor(img_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T15:40:03.282656Z",
     "iopub.status.busy": "2020-09-23T15:40:03.281658Z",
     "iopub.status.idle": "2020-09-23T15:40:03.287643Z",
     "shell.execute_reply": "2020-09-23T15:40:03.286645Z",
     "shell.execute_reply.started": "2020-09-23T15:40:03.282656Z"
    }
   },
   "source": [
    "## Content loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.839549Z",
     "iopub.status.busy": "2020-09-23T16:12:00.838549Z",
     "iopub.status.idle": "2020-09-23T16:12:00.846530Z",
     "shell.execute_reply": "2020-09-23T16:12:00.845533Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.839549Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_content_loss(content_feature, gen_feature, loss_weight=1e-6):\n",
    "    return loss_weight*tf.reduce_sum(tf.square(content_feature - gen_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T15:40:31.949117Z",
     "iopub.status.busy": "2020-09-23T15:40:31.949117Z",
     "iopub.status.idle": "2020-09-23T15:40:31.955069Z",
     "shell.execute_reply": "2020-09-23T15:40:31.954070Z",
     "shell.execute_reply.started": "2020-09-23T15:40:31.949117Z"
    }
   },
   "source": [
    "## Style loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.849521Z",
     "iopub.status.busy": "2020-09-23T16:12:00.848525Z",
     "iopub.status.idle": "2020-09-23T16:12:00.882436Z",
     "shell.execute_reply": "2020-09-23T16:12:00.877447Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.849521Z"
    }
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    x = tf.transpose(x, (2, 0, 1))\n",
    "    features = tf.reshape(x, (tf.shape(x)[0], -1))\n",
    "    gram = tf.matmul(features, tf.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.885425Z",
     "iopub.status.busy": "2020-09-23T16:12:00.884428Z",
     "iopub.status.idle": "2020-09-23T16:12:00.898391Z",
     "shell.execute_reply": "2020-09-23T16:12:00.897394Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.885425Z"
    }
   },
   "outputs": [],
   "source": [
    "def style_loss(style_feature, gen_feature, img_size, loss_weight=1e-6):\n",
    "    S = gram_matrix(style_feature)\n",
    "    G = gram_matrix(gen_feature)\n",
    "    channels = 3\n",
    "    size = img_size[0] * img_size[1]\n",
    "    return loss_weight*tf.reduce_sum(tf.square(S - G))/(4.0*(channels**2)*(size**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.901382Z",
     "iopub.status.busy": "2020-09-23T16:12:00.900386Z",
     "iopub.status.idle": "2020-09-23T16:12:00.913350Z",
     "shell.execute_reply": "2020-09-23T16:12:00.912354Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.901382Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_total_loss(content_tensor, style_tensor, gen_tensor, content_layers, style_layers, img_size, a=0.8, b=0.2):\n",
    "    input_tensor = tf.concat(\n",
    "        [content_tensor, style_tensor, gen_tensor], axis=0\n",
    "    )\n",
    "    features = model(input_tensor)\n",
    "    \n",
    "    content_features = features[content_layers[0]]\n",
    "    \n",
    "    loss = tf.zeros(shape=())\n",
    "    \n",
    "    content_loss = compute_content_loss(content_features[0], content_features[2])\n",
    "    loss += a*content_loss\n",
    "    \n",
    "    total_style_loss = tf.zeros(shape=())\n",
    "    for layer in style_layers:\n",
    "        layer_feature = features[layer]\n",
    "        style_feature = layer_feature[1]\n",
    "        gen_style_feature = layer_feature[2]\n",
    "        layer_style_loss = style_loss(style_feature, gen_style_feature, img_size)\n",
    "        loss +=  (b/len(style_layers)) * layer_style_loss\n",
    "        total_style_loss += layer_style_loss\n",
    "        \n",
    "    return loss, content_loss, total_style_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.915345Z",
     "iopub.status.busy": "2020-09-23T16:12:00.914348Z",
     "iopub.status.idle": "2020-09-23T16:12:00.950252Z",
     "shell.execute_reply": "2020-09-23T16:12:00.949255Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.915345Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_loss_and_grads(content_image_tensor, style_image_tensor, gen_image_tensor, content_layers, style_layers, img_size):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, content_loss, total_style_loss = compute_total_loss(content_image_tensor, style_image_tensor, gen_image_tensor, content_layers, style_layers, img_size)\n",
    "    grads = tape.gradient(loss, gen_image_tensor)\n",
    "    return loss, content_loss, total_style_loss, grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.952247Z",
     "iopub.status.busy": "2020-09-23T16:12:00.951249Z",
     "iopub.status.idle": "2020-09-23T16:12:00.969709Z",
     "shell.execute_reply": "2020-09-23T16:12:00.968713Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.952247Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_loop(content_tensor, style_tensor, gen_tensor, content_layers, style_layers, img_size, optimizer, max_iterations=10000):\n",
    "    for i in range(1, max_iterations+1):\n",
    "        if (i % 100 == 0) or (i == 1) or (i == max_iterations):\n",
    "            loss, content_loss, total_style_loss, grads = compute_loss_and_grads(content_tensor, style_tensor, gen_tensor, content_layers, style_layers, img_size)\n",
    "            optimizer.apply_gradients([(grads, gen_tensor)])\n",
    "            print(f\"iteration {i:8}, loss {loss:.2f}, content loss {content_loss:.2f}, style loss {total_style_loss:.2f}\")\n",
    "            \n",
    "        # show image\n",
    "        if (i % 1000 == 0) or (i == 1) or (i == max_iterations):\n",
    "            fig = plt.figure(figsize=(5, 5))\n",
    "            plt.title(f\"iteration {i}\")\n",
    "            plt.imshow(deprocess_image(gen_tensor))\n",
    "            plt.show()\n",
    "        \n",
    "        # save image\n",
    "        if (i % 200 == 0) or (i == 1) or (i == max_iterations):\n",
    "            save_img_arr = deprocess_image(gen_tensor)\n",
    "            tf.keras.preprocessing.image.save_img(f\"./regenerate_output_img/{i}.jpg\", save_img_arr)\n",
    "    \n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    plt.title(\"final result\")\n",
    "    plt.imshow(deprocess_image(gen_tensor))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.971704Z",
     "iopub.status.busy": "2020-09-23T16:12:00.971704Z",
     "iopub.status.idle": "2020-09-23T16:12:00.985667Z",
     "shell.execute_reply": "2020-09-23T16:12:00.984670Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.971704Z"
    }
   },
   "outputs": [],
   "source": [
    "# neural style transfer output\n",
    "\n",
    "content_layers = ['block5_conv2']\n",
    "style_layers = [\n",
    "    'block1_conv1',\n",
    "    'block2_conv1',\n",
    "    'block3_conv1',\n",
    "    'block4_conv1',\n",
    "    'block5_conv1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:00.987663Z",
     "iopub.status.busy": "2020-09-23T16:12:00.986664Z",
     "iopub.status.idle": "2020-09-23T16:12:01.604013Z",
     "shell.execute_reply": "2020-09-23T16:12:01.604013Z",
     "shell.execute_reply.started": "2020-09-23T16:12:00.987663Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_vgg()\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(\n",
    "    tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1000.0, decay_steps=500, decay_rate=0.9\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:01.607007Z",
     "iopub.status.busy": "2020-09-23T16:12:01.606008Z",
     "iopub.status.idle": "2020-09-23T16:12:01.968619Z",
     "shell.execute_reply": "2020-09-23T16:12:01.967718Z",
     "shell.execute_reply.started": "2020-09-23T16:12:01.606008Z"
    }
   },
   "outputs": [],
   "source": [
    "# load image\n",
    "content_img_path = \"./img/remember.jpg\"\n",
    "style_image_path = \"./img/best_nzk.jpg\"\n",
    "img_size = (500, 500)\n",
    "\n",
    "# base image/target image tensor\n",
    "content_img_tensor = preprocess_image(content_img_path, img_size)\n",
    "style_img_tensor = preprocess_image(style_image_path, img_size)\n",
    "# random image\n",
    "gen_tensor = load_random_noise_tensor(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T16:12:01.969615Z",
     "iopub.status.busy": "2020-09-23T16:12:01.969615Z",
     "iopub.status.idle": "2020-09-23T16:12:30.888327Z",
     "shell.execute_reply": "2020-09-23T16:12:30.885336Z",
     "shell.execute_reply.started": "2020-09-23T16:12:01.969615Z"
    }
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[256,256,3,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/block3_conv2/Conv2D (defined at <ipython-input-15-9b763fffab19>:5) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_compute_loss_and_grads_1260]\n\nFunction call stack:\ncompute_loss_and_grads\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2765b3c0de4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m training_loop(content_img_tensor, style_img_tensor, gen_tensor, \n\u001b[0m\u001b[0;32m      2\u001b[0m               content_layers, style_layers, img_size, optimizer, 15000)\n",
      "\u001b[1;32m<ipython-input-17-a46abba14d1c>\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(content_tensor, style_tensor, gen_tensor, content_layers, style_layers, img_size, optimizer, max_iterations)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_style_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"iteration {i:8}, loss {loss:.2f}, content loss {content_loss:.2f}, style loss {total_style_loss:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chuan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chuan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    648\u001b[0m               *args, **kwds)\n\u001b[0;32m    649\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chuan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\users\\chuan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\chuan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chuan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[256,256,3,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model/block3_conv2/Conv2D (defined at <ipython-input-15-9b763fffab19>:5) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_compute_loss_and_grads_1260]\n\nFunction call stack:\ncompute_loss_and_grads\n"
     ]
    }
   ],
   "source": [
    "training_loop(content_img_tensor, style_img_tensor, gen_tensor, \n",
    "              content_layers, style_layers, img_size, optimizer, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-09-23T16:12:30.889330Z",
     "iopub.status.idle": "2020-09-23T16:12:30.890324Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.imshow(deprocess_image(img_tensor))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-09-23T16:12:30.892317Z",
     "iopub.status.idle": "2020-09-23T16:12:30.893314Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.imshow(deprocess_image(gen_tensor))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
